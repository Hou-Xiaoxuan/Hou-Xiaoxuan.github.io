---
layout:     post   				    # 使用的布局（不需要改）
title:      计组复习笔记 				# 标题 
subtitle:   一定要过啊 #副标题
date:       2020-12-22 				# 时间
author:     Lin_Xuan 						# 作者
header-img: img/post-Note-Head.png 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 复习
    - 笔记
---

# 计组期末复习

&emsp;&emsp;目前未知的六次作业，前四次是数据的存储(整数1，2、浮点数3，4)，第五次是汇编指令与C编码的关系与转换、第六次是内存大小的计算方法(机械硬盘和DRAM内存)

### 复习重点：

- 小题占30分(20分选择，20填空)、涉及PPT的所有细节
- Two different kinds of CU
- IO module和外设
- IO Technology ：三种不同方式的具体细节，重点关注**中断** 
- 浮点数：可以无缝衔接的原因、进制转换 √
- Memory Expansion：位扩展、子扩展、同时扩展
- BUS architecture：不同速度的设备使用怎样的架构
- Instruction addressing mode：不同寻址方式及其优缺点、在那种情况来使用√
- Memory Capacity： SDRAM容量计算(数据总线、地址总线-复用、片选总线)

## 习题课问题：

- CH4.3 26页是怎么看出是小端的？
- CH4.3 28页 栈帧具体做了什么？
- 流水线M阶段阶段操作到底执行了什么Memory和write back有什么差别？

## Chapter 1: 简介

#### 大小端问题

&emsp;&emsp;小端按内存增大的方式储存，即**低位在前、高位在后**。大端则是相反的**高位在前、低位在后**。但是具体在物理内存上的位置的未知的。上述的内存增大是指储存这个数据的内存。如0xabcd，0xab一字节，0xcd一字节。在小段中，计算机把0xcd存在低地址、0xab存在高地址。而大端则是那0xab存在低地址，二八0xcd存到高地址中。(*我们平时的阅读顺序时大端顺序，即从左往右*)

## Chapter 2: 信息的表示和计算

&emsp;&emsp;使用补码进行保存和计算的原因是因为补码可以保证运算正确却是一个Abel群。

&emsp;&emsp;无符号/有符号整型之间的转换规则是二进制形式保持不变

### <font color="red">IEEE 754标准</font> 

&emsp;&emsp;**浮点数的表示**：$(-1)^s\times M*\times2^E$ 

&emsp;&emsp;但是，计算机在储存时不仅仅保存s，significant位M和exponent(阶码)E，而是做了一些调整。

| S(1/1)          | Exp(8/11)                     | Frac(23/52)                 |
| --------------- | ----------------------------- | --------------------------- |
| 符号位，与s相同 | exp filed encodes，不等于阶码 | frac field encodes，不等于M |

&emsp;&emsp;float类型和double类型的精度主要区别在Frac位的保存上。

#### 三种不同的编码形式

*(在计算机内同时使用，应用于不同大小范围的数字)* 

##### Normalized 规格化数

&emsp;&emsp;最常用的类型，用于储存大部分数字，不能储存非常小和无穷的数字

&emsp;&emsp;**特点**：Exp位不等于0或255。

&emsp;&emsp;Exp位是偏置(Biased)储存的，偏置$bias=2^{k-1}$(K是exp位的位数(8或11))。储存方式是$E=Exp+Bias$ 

&emsp;&emsp;Significant位在编码时默认忽略了开头的1(1.xxxxx)。

##### De-normalized 非规格化数

&emsp;&emsp;用来储存非常小，接近0的数字

&emsp;&emsp;**特点**：Exp位全部为0。

&emsp;&emsp;由于Exp位的结果位0，如果依照上面的偏置规则来看，E位应该为0-Bias。但是并不是，我们对结果做+1处理。所以实际上$E=1-Bias$。(*无缝衔接*)

&emsp;&emsp;而Significant位则默认省略了0(0.xxxxx)

##### Special Values 特殊情况

&emsp;&emsp;Exp位全为1，而frac位全为0时代表一个非常大的数（*超过储存范围，∞*）

&emsp;&emsp;而同时，frac不全为0代表出错了，结果不是数字

&emsp;&emsp;**PS**：非规格化数不以规格化数储存的原因之一是因为数字太小，继续去增大M，储存E的位数就不够用了。

&emsp;&emsp;**PS(<font color="red">无缝衔接的原因</font>)**：非规格化数对E做加1处理、最大的非规格化数和最大的规格化数非常接近

## Chapter 3：指令编码和指令集



### 设计指令集需要的点：

- 操纵数种类 Operation repertoire
- 数据类型Data types
- 指令形式 Instruction format
- 寄存器个数
- 寻址方式

### Types of Operands

<center><img src="https://s3.ax1x.com/2020/12/30/rOyUPI.png" style="zoom:67%;" /></center>



&emsp;&emsp;Imm(%ebp) 取该地址的内存偏移imm位

&emsp;&emsp;不能直接内存到内存

### <font color="red">寻址方式</font> 

- Immediate //立即数：直接存数据
- Direct //直接：直接存数据的的地址
- Indirect //见解：存数据地址的地址
- Register //寄存器：存数据的寄存器编号
- Register Indirect //寄存器间接寻址：存数据寄存器编号的地址
- Displacement Addressing //基址寻址：存到操作数地址的到基准的距离
  - Relative //相对寻址
  - Base-Register //基址寄存器寻址：寄存器里储存了偏移量
  - Indexing //变址寻址：储存指向偏移量的数据·的地址

**如何区分**：Opcode的前几位是mode field，表明了寻址方式

### 如何设计指令集？

- Instruction Length
- Allocation of Bits
  -  Number of addressing modes
  -  Number of operands
  -  Register vs. memory
  -  Number of register sets
  -  Address range
  -  Address granularity

### 使用指令

<center><img src="https://s3.ax1x.com/2020/12/30/rOyUPI.png" alt="rOyUPI.png" style="zoom:67%;" /></center>

&emsp;&emsp;这里的指令的顺序同计组实验时的清华实验箱的指令顺序相反。

### 指令集分类

#### CISI：复杂指令集(intel、AMD)

##### Traits

- 每条指令执行更多的操作
- 程序更小
- 占用空间更少

##### Why need  RISI？

- 编译器开始流行

- 很多指令使用频率很低
- 一些复杂的指令执行得很慢

#### RISI：精简指令集

##### Traits

- Small, highly optimized set of instructions

- Uses a load-store architecture

- Short execution time

- **Pipelining** 

- Many registers

##### Advantage:

- Less transistors needed in RISC//需要的晶体管较少

- RISC processors have shorter design cycles //设计周期较短

- RISC instructions take less clock cycles than CISC instructions//执行周期较短

## Chapter 4： Processor Architecture

### Organization

&emsp;&emsp;*Y86是作者自己构想的一套处理器、并没有在现实中使用。*

&emsp;&emsp;在设计处理器的时候，一般需要考虑四个方面：使用者(Coder and Complier)看到的模块、寄存器的组织、指令集的设计和指令的编码和译码。

&emsp;&emsp;Instruction has initial byte, spiting into two-bit parts: `i-code` and `i-funtion`

### Processor Implementations

#### Five Stages 

- **Fetch **(取址F)

  Extract the `i-code` and `i-fun`

  Fetch register in `RA` and `RB`

  Fetch  a 4-byte constant word in `valC`

  compute `ValP` as the next address of instructions

- **Decode** (译码D)

  Read up to 2 `oprands` from the register file as `ValA` or `ValB` (*for some instructions, it reads %esp rather than rA and rB*)

- **Execute** (执行E)

  the result as `valE` 

- **Visit Memory **(访存M)

  if we read value, it was `ValM` 

- **Write back** (写回W)

- **PC update** (更新PC)

### Instruction Pip-line(流水线及优化) 

&emsp;&emsp;**SEQ(顺序执行)的缺点**：Low Throughout(吞吐量低), Wast Resources(浪费资源), and Big Latency(延迟高)

&emsp;&emsp;**Pipeline(流水线)的特点**：有效增加了 **throughout**(*The number of customers served per unit time*), 但是同时也增加了 **latency**(*the time required to service an individual customer*) 

&emsp;&emsp;**latency的组成**：Latency主要由Combinational logic和register两部分的延迟组成。而流水线将Combinational拆分，增加了register部分的延迟，但是收获了较大的吞吐量。</br>&emsp;&emsp;但是显然，拆分的数量影响着流水线的效率。当拆分过多时，增加的register延迟太高，反而会导致整体吞吐量的下降。

#### **Y86的流水线实现**：

&emsp;&emsp;将PC更新调整为一个周期的第一个阶段。流水线一共有5个周期

1. F：hold PC的下一个值
2. D：介于Fetch和decode中间，hold decode要使用的fetch得到的信息
3. E：decode和execute中间，hold decode得到的信息和寄存器读出来的值
4. M：execute和memory之间，hold指令执行得到的结果
5. W：memory和feedback之间，在执行ret操作后，该阶段把结果存入寄存器，同时将地址信息返回给PC用于计算下一条指令的地址

**Pipeline hazards(流水线缺陷)**：

- Data dependency(数据依赖性)

&emsp;&emsp;数据依赖性会发生在很多地方：

&emsp;&emsp;**Register**：数据缺陷发生在一条指令写入信息，一条指令读取信息。但是可能上一条指令的M阶段还没有执行，这条指令就要实行D阶段了，因此会读取到错误的信息。

&emsp;&emsp;**PC**：PC还没有被正确更新，下一跳指令一键要执行F阶段了，发生冲突

&emsp;&emsp;**Memory**：同Register

&emsp;&emsp;**Condition Code**：在jmp等指令执行前，还没更新Condition

&emsp;&emsp;**Statue Register**：同Condition code

&emsp;&emsp;#### Avoiding(避免流水线缺陷)：

&emsp;&emsp;*流水线的avoiding是在硬件层面实现的。虽然在代码中加入nop空转指令也可以达到相同的目的，但是这要求做额外的代码工作，不太讨论范围中。* 

&emsp;&emsp;最常用的方法就是stalling(等待)，等到前面的指令执行结束在执行就可以了。例如在指令间插入**bubble**来延缓下一条指令的执行。

<center><img src="https://s3.ax1x.com/2021/01/04/sCwGcR.png" alt="bubble" style="zoom:67%;"></center>

&emsp;&emsp;Stalling的缺点也很明显——浪费时间

&emsp;&emsp;当然，也可以使用Forwarding方法来避免冲突，即通过管道，间吓一跳指令要使用的值预先传递下去，而不是等到M阶段再储存。

&emsp;&emsp;Forwarding的缺点在于，需要添加很多额外的信号和寄存器来完成操作。

#### 一些其他的东西：

&emsp;&emsp;对比Jxx,Ret,Call三个指令，Call指令不会引发pipeline hazards，因为Call指令的PC计算在取指阶段就已经完成了，而Jxx和Ret则分别在PC update和Memory阶段才确定

## Chapter 5： Memory

### Memory Hierarchy(内存的层级)

&emsp;&emsp;不同的储存介质的速度、容量和价格有着明显的区分。他们之间的层级关系是计算机结构的核心之一。

#### Storage technologies and trends

##### **Read Only Memory**(ROM)：

&emsp;&emsp;更**Non-Volatile**(稳定)一些，种类跟多，如：

​&emsp;&emsp;ROM: 掩模型，永远无法改变，数据在制造过程中写入。

​&emsp;&emsp;PROM:可编程型。可以编程一次，之后保险丝断裂，变成只读。

​&emsp;&emsp;EPROM:(Erase Programmable)，经过紫外线照射可以查出数据重新写入。

​&emsp;&emsp;EEPROM:电子可擦除，比较稳定，用来保存一些断电时的少量信息。

​&emsp;&emsp;**Flash Memory**:常见的手机内存卡的介质。相对于(EEP)RAM来书，读写快，容量大。相对于RAM来说要更稳定。但是进行1000,000左右的读写后就会失效。

##### **Random Access Memory**：

&emsp;&emsp;比较**Volatile**(不稳定)，用在Cache(SRAM)和内存(DRAM)。RAM通常被封装成芯片，由cell(大小1 bit)组成，多个芯片组合成出储存器。

###### **Static RAM**：

&emsp;&emsp;每个cell的实质4/6-晶体管电路。在**通电**条件下信息可以永久保存，抵抗电子辐射等干扰的能力较强。同DRAM相比，速度和价格会高很多。

###### DRAM：

&emsp;&emsp;DRAM的每个cell是电容，用一个晶体管来访问。由于电容会不断的损耗电量，因此需要不断的进行充电(*per 10-100ms*)。同时对电子干扰很敏感。速度比SRAM慢，但是比较便宜。

##### Key Characteristic of Main Memory(一些重要的特征，如<font color='red'>容量计算和扩容方式</font>)：

&emsp;&emsp;**Capacity**:储存的容量指的是他能储存的二进制位数。由公式$Capacity=NumbersOfUnit\times Word$计算得到。

###### <font color='red'>Convertional DRAM Organization</font>:

&emsp;&emsp;DRAM一般命名为d×w 型，意思是有d个supper ceil(*单元*)，每个ceil储存了w bit数据。

<center><img src="https://s3.ax1x.com/2021/01/04/sCw39J.png" alt="DRAM结构" style="zoom:67%;" /></center>

&emsp;&emsp;在读取数据是，有**地址总线**传入地址信息，由**数据总线**将目标数据传出。传入地址时，行地址和列地址分开传送，因此总线可以**复用**。而数据信息则是一次传出，没有复用。

&emsp;&emsp;如上图中的16×8 DRAM chip，有两根地址总线，分别传送二位2进制(十进制4)的行和列信息。而数据总线有八根，传送八位2进制的数据。

&emsp;&emsp;在制作内存条是，有多片DRAM并列放在一起(*如下图*)。但是在读写时，并不是按照一片一片的顺序进行的，而是每次同时读所有chip的相同位置(*就是竖着读写的*)。因此为了找到目标数据所在的ceil，还需要**片选总线**。

<center><img src="https://s3.ax1x.com/2021/01/04/sCw839.png" alt="内存条结构" style="zoom:67%;" /></center>

###### Read/Write Transaction:

&emsp;&emsp;CPU和Memory以I/O Bridge为媒介，通过控制总线、地址总线和数据总线来交换信息，进行memory的读写等操作。

###### <font color="red">Memory Extension(内存扩展)：</font> 

&emsp;&emsp;**Word(字长)**：在此处指的是单片芯片的容量(及总地址的大小)

&emsp;&emsp;**Bit(位长)**：指的是每次取数据时取的长度

&emsp;&emsp;在计算机的内容不足时，为了扩展内存我们需要将多组芯片串到一起。而在硬件上处理时，就有几种不同的方案。比如当前计算机使用的是一片$1k×8$位的芯片,现在需要将内存扩大一倍。

&emsp;&emsp;当前状态下，需要8根数据总线(*Bit长度为8位*)、10根地址总线(*总共1K的储存单元*)。

&emsp;&emsp;**位扩展**：每片芯片的字长不变(1K)，将每次选取的数据的位数扩充一倍，数据总线变成16根，得到$1k\times 16$的芯片。

&emsp;&emsp;**字扩展**：不改变位长，而是增加总的地址数量，增加一根地址总线，得到$2K \times 8$的芯片。

&emsp;&emsp;**字、位同时扩展**：两个扩展方式可以同时进行(*在总线的数量足够的情况下*)

##### Disk(硬盘)

&emsp;&emsp;这里的硬盘专指机械硬盘。机械硬盘由若干个Platter(盘片)重叠而成，每个Platter由上下两个Surface(盘面)，盘面上有若干个同心圆环状的track(磁道)，而Surface也被等分成了若干个Sectors(扇区)。

&emsp;&emsp;**Capacity**：计算硬盘的容量，首先要知道每个Sector的容量，每个track的Sectors数量(对所有的磁道来说为一个定值)和每个Surface上tracks的数量以及Platers的数量，进行乘法计算即可。

&emsp;&emsp;**Disk Access Time**：

&emsp;&emsp;在访问某一块的数据时，read/write head(读写磁头)先根据地址移动到对应的磁道，接着等待匀速转动的磁盘转动到对应的扇区，然后进行读写。因此磁盘的读写时间包括三部分，及seek time(寻道时间)、rotational time(等待旋转的时间)和transfer time(数据传动时间)。而磁盘在读取时，总是每次读取完整的一个Sector。

&emsp;&emsp;**Tavg seek**：平均寻道时间，一般为题目给的定制，与制作工艺有关

&emsp;&emsp;**Tavg rotation**：平均等待时间，与磁盘的转速(RPM)有关，计算方式为磁盘旋转一圈的时间的一半。

&emsp;&emsp;**Tavg transfer**：数据的读取时间，为磁盘旋转过该扇区的时间，同rotation time相比很,可以忽略。

&emsp;&emsp;机械硬盘的速度比S/DRAM的速度慢的多大概为SRAM的40,000倍，DRAM的2,500倍。

##### Solid State Disk(SSD固态硬盘)

&emsp;&emsp;**特点**：以units of pages为单位进行读写，每次写入前需要擦除整个pages，100,000次擦除后损坏。

&emsp;&emsp;固态硬盘随机read的速度比顺序read要满一倍左右，随机write的速度却会比顺序write要慢十几倍。因为随机写入时，擦除一个界面时要花费大量的时间，同时还要备份没有更改的部分数据。

&emsp;&emsp;速度上，SSD比机械快得多，当时也贵得多，然而依旧比DRAM慢得多(*所以啊，打游戏慢的话还得换大内存啊，SSD解决不了多大问题！——林老师*)

#### Locality of reference(访问局部性)

&emsp;&emsp;有时间的局部性和空间的局部性。

&emsp;&emsp;Temporal locality(时间局部性)体现在是使用相同的内存时，由于cashe的存在，速度会比随机访问快得多。

&emsp;&emsp;Spatial locality(空间局部性)体现在访问临近的内存是的速度更快

&emsp;&emsp;在写程序时，考虑到时间局部性和空间局部性，能在相同的时间复杂度上使程序拥有更快的速度。具体原因与计算机的cashe机制有关，在后米娜讨论。

#### 内存结构中的Cashe(简单介绍)

<center><img src="https://s3.ax1x.com/2021/01/08/smzEo6.png" alt="内存结构" style="zoom: 50%;" /></center> 

<center>计算机的内存结构图</center> 

&emsp;&emsp;Cashe缓存了Memory的一部分。在访问内存时，优先在cashe中查找。能找到的话(hit)直接访问cashe速度要快得多。而找不到的话(miss)则要直接从内存中读取，速度会慢得多。

<center><img src="https://s3.ax1x.com/2021/01/08/smzZFK.png" alt="内存结构" style="zoom: 50%;" /></center> 

<center>Example of Hierarchy</center> 

&emsp;&emsp;计算机中最重要的结构之一。层级越往上访问速度越快，价格越贵，越往下访问速度越慢，价格越便宜。使用越频繁的数据放到上层，使用没那么频繁的放在下增，保证价格低廉的同时有很快的处理速度，使得计算机走进千家万户。

##### Types of misses

&emsp;&emsp;**cold miss**：系统刚开始运行，缓存区时空的，肯定会miss。

&emsp;&emsp;**Conflict miss**：Cashe在缓存时有一定的规则，一般缓存去特定的位置会缓存满足特定条件位置的数据。如(*只是举例假象的规则，真是情况规则不同*)缓存i只缓存memory中每个分块的第i位。这样，但访问的两个数据位于不同分块的相同位置时，每次访问都会冲突(例如0，8在缓存区使用相同的位置，0 8 0 8 0 8这样访问，尽管缓存区未满，除第一次外每次访问都冲突)

### Cache(具体实现)

&emsp;&emsp;Cache是一种SRAM-based Memory，集成在硬件上，储存了主存的一小部分来实现更快的读写。Cache中储存的是CPU最频繁访问/刚刚访问过的数据。

#### Cache Organization and operation

##### Organization：

<center><img src="https://s3.ax1x.com/2021/01/17/syu4de.png" alt="Cache Organization" style="zoom: 50%;" /><br>Cache 结构图</center>

&emsp;&emsp;Cache是一种S，E，B结构，即有$S=2^s$个sets，每个sets有$E=2^e$列(块)，每个块里有$B=2^b$bytes(8 bits)的数据。因此，Cache的容量$Capacity=S\times E\times B(bytes)$。

&emsp;&emsp;而每个Block中，分为三部分：valid bit(是否可用)，tag()和data(储存的实际数据)。

&emsp;&emsp;同时，一个数据的内存地址也可以分为三部分：tag(t bits)、set index(s bits)和block offset(b bits，偏移量)。

##### Read：

&emsp;&emsp;Cache的大小是远远小于Memory的，所以Cash的每个block会对应超过其容量的数据。如何区分这些会使用同一个block单元的数据呢？通过tag位和index位。

&emsp;&emsp;在去cache中读数据时，地址的index位表明了这个地址如果被成功缓存会在那个sets里面。依次查看set中的每个block的valid位和tag位。如果valid显示位1(可用)且该block的tag位与地址上的tag位吻合，则说明改bolok中储存的正好就是我们想要读取的数据，此时**Cache hit**。由于block的data可能不止1字节，接下来使用地址offset位来决定我们从block的第几个字节开始读取数据。如果在上述过程中没有任何一个block满足条件，则**Cache miss**，需要去memory中直接寻找数据，更新Cache。

&emsp;&emsp;同时注意一点，Cache的更新不是以字节位单位的，而是以block位单位的。一旦发生miss，即使改block中储存着其数据的缓存，也会被清除掉。同时，地址上偏移量的二进制大小也就是一个block的data单元的大小(设计决定)。

&emsp;&emsp;比如，对于4 bits的地址，$t:s:b=1:2:1$，地址0 00 1，tag为0，最为区分1 00 1和0 00 1两个不同模块的标签；index=0，该数据缓存在set 0中；offset为1为，说明每个block的data块有两字节，而该地址的数据缓存在block data的第1个自己(从0计数)。

**问**：*为什么index位要选在地址的中间而不是高位？* 

**答**：
&emsp;&emsp;为了使得内存中连续的地址不会使用同一个set，Cache能保存的最大连续地址的大小被block的大小所限制。程序连续读写内存时，反而会引发Cache的不断更新，降低效率。

##### Examples of Cache：

**直接相连映射 Direct-Map Caches**： E= 1，每个set里面只有1个data block。产生miss直接擦除set，替代。

**组相连映射 E-Way Set Associative Caches**：$E\geqslant2$,产生miss只会擦除，替代对应的block。

**直接相连映射 Full Associative Caches**： 只有一个大set。此时，对应的地址也只有tag和offset两块了。

##### Write：

**Hit**：有两种处理方式

​	&emsp;&emsp;Write-through：直接写回主存中。

​	&emsp;&emsp;Write-back：将数据更新到Cache中，直到Cache被替换更新才将数据写入主存(会有dirty bit，即cache与memory不一致)。

**Miss**：

​	&emsp;&emsp;Write-allocate：写入缓存区(在多次写入时更优秀)

​	&emsp;&emsp;No-Write-allocate：直接写入主存。

&emsp;&emsp;一般都写入缓存，要么都直接写入主存，hit和miss时保持一致。

&emsp;&emsp;L1层中，在hit的情况下，读写大概花费1-2(5-20 in L2)个时钟周期，而miss后去主存的读取需要50-200个始终周期。因此，$97\%$的命中率实质上比$99\%$慢一倍。

#### Performance impact of caches

&emsp;&emsp;对`intel i7`芯片来说，$L_1$层cache有32KB`i-cache`和32KB`d-cache`(指令缓存、数据缓存)，$L_2$层有256KB，$L_3$层8M。而每个block的大小都是64 bytes

##### Locality:

&emsp;&emsp;locality本质上就是增高cache的hit率。以下面的单个计算矩阵乘法$C=A\times B$的c代码为例子，都是三重循环，复杂度都是$O(n^3)$。但是Cache的命中率却不同，从而影响执行效率。(*我们假设Cache的一个block中B=32,即能存4个64位数据，同时n很大，存不下多行来方便讨论*)

**Version 1(IJK or JIK)**：

```c++
int i,j,k;
double sum;
for(i=0;i<n;i++)
{
    for(j=0;j<n;j++)
    {
        sum=0.0;
        for(k=1;k<=n;k++)
            sum+=a[i][k]*b[k][j];
        c[i][j]=sum;
    }
}
```

&emsp;&emsp;在最内层的循环中，在矩阵A中，元素时一行一行访问的，misses率**0.25**(一个block能存4个都变了，每4次更新一次)。在矩阵B中，元素是按列访问的，misses率**1.0**。而在矩阵C中，元素一个一个访问，只有第一次可能冲突，≈**0.0**。

**Version 2(IKJ or KIJ)**：

```c++
int i,j,k;
double r;
for(i=0;i<n;i++)
    for(k=0;k<n;k++)
    {
        r=a[i][k];
        for(j=0;j<n;j++)
            	c[i][j]+=r*b[k][j];
    }
```

&emsp;&emsp;在最内层的循环中，在矩阵A中，元素只访问一个，misses率**0.0**。在矩阵B中，元素是按行访问的，misses率**0.25**。而在矩阵C中，元素按行访问，**0.25**。

**Version 3(KJI or JKI)**：

```c++
int i,j,k;
double r;
for(k=0;k<n;k++)
    for(j=0;j<n;j++)
    {
        r=b[k][j];
        for(int i=1;i<=n;k++)
            c[i][j]+=a[i][k]*r;
    }
```

&emsp;&emsp;在最内层的循环中，在矩阵A中，元素按列访问，misses率**1.0**。在矩阵B中，元素是按个访问的，misses率**0.0**。而在矩阵C中，元素按列访问，**1.0**。

&emsp;&emsp;对比可以看出，version 2是最优的，version 3是最差的。当足够大时(大于700),version1的每次读写大概需要25个周期，version 2大概5个，而version需要50个以上的时钟周期，差异很大。

### Virtual Memory

## Chapter 6： IO System



## Chapter 7： Cu












